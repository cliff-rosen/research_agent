# Workflow

## Core Analysis Components

- Question decomposition into atomic claims/queries
- Identification of implicit assumptions
- Definition of scope boundaries
- Success criteria specification
- Stakeholder perspective mapping

## Key Behaviors

- Creates quantitative scoring systems for each major aspect
- Establishes clear thresholds for iteration triggers
- Enables tracking of progress across all dimensions
- Creates explicit quality gates that must be passed
- Ties back to the original atomic claims throughout

## Workflow Steps

# **Research Workflow**

| **Step** | **Name**                           | **Input**                                                             | **Output**                                                                                                                                                                                                                                  | **Description**                                          |
| -------- | ---------------------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------- |
| **1**    | **Question Submission**            | - Raw question from user<br>- Any provided context                    | - Question ID<br>- Initial metadata:<br>&nbsp;&nbsp;- Timestamp<br>&nbsp;&nbsp;- Domain area<br>&nbsp;&nbsp;- User context                                                                                                                  | Basic receipt and logging of the question                |
| **2**    | **Question Refinement**            | - Raw question<br>- Initial metadata                                  | - Refined question with:<br>&nbsp;&nbsp;- Explicit scope<br>&nbsp;&nbsp;- Time boundaries<br>&nbsp;&nbsp;- Geographic scope<br>&nbsp;&nbsp;- Domain limitations<br>- Defined key terms<br>- Required context<br>- Clarified ambiguities     | Interactive process to clarify and bound the question    |
| **3**    | **Question Analysis**              | - Refined question<br>- Defined scope                                 | - Core components identified<br>- Dependencies mapped<br>- Required evidence types<br>- Key claims to verify<br>- Information types needed                                                                                                  | Systematic breakdown of question requirements            |
| **4**    | **Success Criteria**               | - Core components<br>- Required evidence types                        | - Quality thresholds<br>- Coverage requirements<br>- Confidence targets<br>- Validation methods<br>- Iteration triggers                                                                                                                     | Define what constitutes a complete answer                |
| **5**    | **Query Expansion**                | - Core components<br>- Key claims<br>- Required evidence              | - Search term matrix<br>- Alternative phrasings<br>- Required contexts<br>- Exclusion terms<br>- Source type requirements                                                                                                                   | Develop comprehensive search strategy                    |
| **6**    | **Source Collection and Analysis** | - Search term matrix<br>- Source requirements<br>- Quality thresholds | - Evidence database with:<br>&nbsp;&nbsp;- Source quality scores<br>&nbsp;&nbsp;- Relevant extracts<br>&nbsp;&nbsp;- Claim mappings<br>&nbsp;&nbsp;- Coverage analysis<br>&nbsp;&nbsp;- Information gaps<br>&nbsp;&nbsp;- Confidence scores | Identify, evaluate, and extract information from sources |
| **7A**   | **Answer Generation**              | - Evidence database<br>- Core components<br>- Success criteria        | - Draft answer<br>- Evidence mapping<br>- Confidence scores<br>- Gap analysis                                                                                                                                                               | Create initial answer version                            |
| **7B**   | **Answer Evaluation**              | - Draft answer<br>- Success criteria<br>- Quality thresholds          | - Quality assessment<br>- Coverage analysis<br>- Gap identification<br>- Improvement needs                                                                                                                                                  | Evaluate answer against requirements                     |
| **7C**   | **Answer Iteration**               | - Quality assessment<br>- Improvement needs<br>- Evidence database    | - Refined answer<br>- Updated scores<br>- Iteration log<br>- Progress metrics                                                                                                                                                               | Improve answer until requirements are met                |
| **8**    | **Final Production**               | - Approved answer<br>- Full documentation<br>- Quality metrics        | - Final answer package:<br>&nbsp;&nbsp;- Complete response<br>&nbsp;&nbsp;- Evidence summary<br>&nbsp;&nbsp;- Quality documentation<br>&nbsp;&nbsp;- Confidence statement                                                                   | Deliver completed answer package                         |

### Generated Evaluation Checklists

#### A. Source Quality Checklist

Score each source (1-5) on:

- Authority (credentials, reputation, expertise level)
- Recency (publication date relevance)
- Methodology rigor
- Data completeness
- Peer review status
- Conflicts of interest
- Citation network strength

#### B. Information Extraction Checklist

For each extracted information nugget, evaluate:

- Direct relevance to atomic claims (1-5)
- Evidence type classification
  - Primary research
  - Secondary analysis
  - Expert opinion
  - Anecdotal evidence
- Contextual completeness (1-5)
- Methodology transparency (1-5)
- Statistical significance (where applicable)
- Effect size (where applicable)

#### C. Conflict Resolution Rubric

For each identified conflict:

- Evidence strength differential
- Methodology comparison
- Sample size/scope differences
- Timeline considerations
- Definition/terminology disparities
- Geographic/cultural context variations
- Stakeholder bias assessment

#### D. Answer Completeness Checklist

Verify:

- All atomic claims addressed
- Evidence provided for each claim
- Uncertainty levels specified
- Alternative viewpoints represented
- Methodology limitations acknowledged
- Context adequately explained
- Assumptions explicitly stated
- Scope boundaries respected

### 2.3 Progress Tracking Metrics

For each subsequent step, track:

- Completion percentage of relevant checklists
- Average scores on quality metrics
- Number of unresolved conflicts
- Coverage of identified stakeholder perspectives
- Information gaps remaining
- Uncertainty levels by claim

### 2.4 Iteration Triggers

Define specific thresholds that trigger return to previous steps:

- Source quality scores below 3/5
- Information gaps in critical areas
- Unresolved high-impact conflicts
- Stakeholder perspective coverage below 80%
- Answer completeness score below 4/5

### 2.5 Final Quality Gates

Establish pass/fail criteria for:

- Minimum source quality averages
- Maximum acceptable uncertainty levels
- Required stakeholder perspective coverage
- Essential context inclusion
- Evidence strength thresholds
- Conflict resolution completeness

## Integration with Other Steps

### Step 3: Query Expansion

- Use atomic claims to generate claim-specific search terms
- Map stakeholder terminology variations
- Track coverage of success criteria

### Step 4: Source Identification

- Apply source quality checklist
- Track authority coverage gaps
- Map sources to atomic claims

### Steps 5-6: Information Extraction & Analysis

- Apply extraction checklist to each nugget
- Track evidence type distribution
- Monitor claim coverage

### Step 7: Conflict Resolution

- Apply resolution rubric to each conflict
- Track resolution progress
- Document resolution rationale

### Steps 8-11: Answer Production & Refinement

- Use completeness checklist for evaluation
- Track quality metrics through iterations
- Document threshold compliance
